2019-07-03T09:37:18.728+0000 I CONTROL  [main] Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'
2019-07-03T09:37:18.732+0000 I CONTROL  [initandlisten] MongoDB starting : pid=1 port=30003 dbpath=/data/db 64-bit host=31346c127eed
2019-07-03T09:37:18.733+0000 I CONTROL  [initandlisten] db version v4.0.10
2019-07-03T09:37:18.735+0000 I CONTROL  [initandlisten] git version: c389e7f69f637f7a1ac3cc9fae843b635f20b766
2019-07-03T09:37:18.736+0000 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 1.0.2g  1 Mar 2016
2019-07-03T09:37:18.736+0000 I CONTROL  [initandlisten] allocator: tcmalloc
2019-07-03T09:37:18.737+0000 I CONTROL  [initandlisten] modules: none
2019-07-03T09:37:18.737+0000 I CONTROL  [initandlisten] build environment:
2019-07-03T09:37:18.739+0000 I CONTROL  [initandlisten]     distmod: ubuntu1604
2019-07-03T09:37:18.740+0000 I CONTROL  [initandlisten]     distarch: x86_64
2019-07-03T09:37:18.741+0000 I CONTROL  [initandlisten]     target_arch: x86_64
2019-07-03T09:37:18.742+0000 I CONTROL  [initandlisten] options: { net: { bindIpAll: true, port: 30003 }, replication: { replSet: "my-mongo-set" }, systemLog: { destination: "file", path: "mongo.log" } }
2019-07-03T09:37:18.745+0000 I STORAGE  [initandlisten] 
2019-07-03T09:37:18.746+0000 I STORAGE  [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine
2019-07-03T09:37:18.747+0000 I STORAGE  [initandlisten] **          See http://dochub.mongodb.org/core/prodnotes-filesystem
2019-07-03T09:37:18.748+0000 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=487M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),statistics_log=(wait=0),verbose=(recovery_progress),
2019-07-03T09:37:19.880+0000 I STORAGE  [initandlisten] WiredTiger message [1562146639:880208][1:0x7fc2b639aa80], txn-recover: Set global recovery timestamp: 0
2019-07-03T09:37:19.901+0000 I RECOVERY [initandlisten] WiredTiger recoveryTimestamp. Ts: Timestamp(0, 0)
2019-07-03T09:37:19.925+0000 I CONTROL  [initandlisten] 
2019-07-03T09:37:19.926+0000 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2019-07-03T09:37:19.928+0000 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2019-07-03T09:37:19.929+0000 I CONTROL  [initandlisten] 
2019-07-03T09:37:19.935+0000 I STORAGE  [initandlisten] createCollection: local.startup_log with generated UUID: fc69e8c3-7e38-44b6-89eb-32fef173dbf2
2019-07-03T09:37:19.968+0000 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'
2019-07-03T09:37:19.974+0000 I STORAGE  [initandlisten] createCollection: local.replset.oplogTruncateAfterPoint with generated UUID: 6d5e2482-c8ea-4c9e-b781-063736a455a3
2019-07-03T09:37:19.992+0000 I STORAGE  [initandlisten] createCollection: local.replset.minvalid with generated UUID: b2a5b19f-1554-4e94-a399-8b2a28c6cec5
2019-07-03T09:37:20.024+0000 I REPL     [initandlisten] Did not find local voted for document at startup.
2019-07-03T09:37:20.025+0000 I REPL     [initandlisten] Did not find local Rollback ID document at startup. Creating one.
2019-07-03T09:37:20.025+0000 I STORAGE  [initandlisten] createCollection: local.system.rollback.id with generated UUID: 8570efb9-cb74-4b73-91ec-2e6a23654ea7
2019-07-03T09:37:20.051+0000 I REPL     [initandlisten] Initialized the rollback ID to 1
2019-07-03T09:37:20.052+0000 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2019-07-03T09:37:20.056+0000 I NETWORK  [initandlisten] waiting for connections on port 30003
2019-07-03T09:37:20.057+0000 I CONTROL  [LogicalSessionCacheRefresh] Sessions collection is not set up; waiting until next sessions refresh interval: Replication has not yet been configured
2019-07-03T09:37:20.058+0000 I CONTROL  [LogicalSessionCacheReap] Sessions collection is not set up; waiting until next sessions reap interval: config.system.sessions does not exist
2019-07-03T09:37:23.711+0000 I NETWORK  [listener] connection accepted from 172.22.0.4:60130 #1 (1 connection now open)
2019-07-03T09:37:23.731+0000 I NETWORK  [conn1] end connection 172.22.0.4:60130 (0 connections now open)
2019-07-03T09:37:23.737+0000 I NETWORK  [listener] connection accepted from 172.22.0.4:60134 #2 (1 connection now open)
2019-07-03T09:37:23.739+0000 I NETWORK  [conn2] received client metadata from 172.22.0.4:60134 conn2: { driver: { name: "NetworkInterfaceTL", version: "4.0.10" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2019-07-03T09:37:23.742+0000 I ASIO     [Replication] Connecting to mongo1:30001
2019-07-03T09:37:25.763+0000 I NETWORK  [listener] connection accepted from 172.22.0.3:60196 #5 (2 connections now open)
2019-07-03T09:37:25.764+0000 I NETWORK  [conn5] end connection 172.22.0.3:60196 (1 connection now open)
2019-07-03T09:37:25.787+0000 I STORAGE  [replexec-0] createCollection: local.system.replset with generated UUID: d67281a5-49d4-4bdc-bf8f-117bec435c52
2019-07-03T09:37:25.804+0000 I NETWORK  [listener] connection accepted from 172.22.0.3:60200 #7 (2 connections now open)
2019-07-03T09:37:25.807+0000 I NETWORK  [conn7] received client metadata from 172.22.0.3:60200 conn7: { driver: { name: "NetworkInterfaceTL", version: "4.0.10" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2019-07-03T09:37:25.812+0000 I ASIO     [Replication] Connecting to mongo2:30002
2019-07-03T09:37:25.817+0000 I REPL     [replexec-0] New replica set config in use: { _id: "my-mongo-set", version: 1, protocolVersion: 1, writeConcernMajorityJournalDefault: true, members: [ { _id: 1, host: "mongo1:30001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "mongo2:30002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 3, host: "mongo3:30003", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: -1, catchUpTakeoverDelayMillis: 30000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5d1c7753118a4b41d3989edb') } }
2019-07-03T09:37:25.818+0000 I REPL     [replexec-0] This node is mongo3:30003 in the config
2019-07-03T09:37:25.818+0000 I REPL     [replexec-0] transition to STARTUP2 from STARTUP
2019-07-03T09:37:25.821+0000 I ASIO     [Replication] Connecting to mongo2:30002
2019-07-03T09:37:25.821+0000 I REPL     [replexec-1] Member mongo1:30001 is now in state SECONDARY
2019-07-03T09:37:25.821+0000 I REPL     [replexec-0] Starting replication storage threads
2019-07-03T09:37:25.823+0000 I CONNPOOL [Replication] Ending idle connection to host mongo2:30002 because the pool meets constraints; 1 connections to that host remain open
2019-07-03T09:37:25.832+0000 I STORAGE  [replexec-0] createCollection: local.temp_oplog_buffer with generated UUID: 50152fac-ec5d-4e31-b786-676a1e12fea9
2019-07-03T09:37:25.838+0000 I REPL     [replexec-3] Member mongo2:30002 is now in state STARTUP2
2019-07-03T09:37:25.853+0000 I REPL     [replication-0] Starting initial sync (attempt 1 of 10)
2019-07-03T09:37:25.855+0000 I STORAGE  [replication-0] Finishing collection drop for local.temp_oplog_buffer (50152fac-ec5d-4e31-b786-676a1e12fea9).
2019-07-03T09:37:25.857+0000 I STORAGE  [replication-0] createCollection: local.temp_oplog_buffer with generated UUID: a8b0eb08-007c-4228-b957-923085d7972c
2019-07-03T09:37:25.872+0000 I REPL     [replication-0] sync source candidate: mongo1:30001
2019-07-03T09:37:25.873+0000 I REPL     [replication-0] Initial syncer oplog truncation finished in: 0ms
2019-07-03T09:37:25.873+0000 I REPL     [replication-0] ******
2019-07-03T09:37:25.874+0000 I REPL     [replication-0] creating replication oplog of size: 2349MB...
2019-07-03T09:37:25.875+0000 I STORAGE  [replication-0] createCollection: local.oplog.rs with generated UUID: aef22b59-11a9-4640-b280-67509d6e43e6
2019-07-03T09:37:25.882+0000 I STORAGE  [replication-0] Starting OplogTruncaterThread local.oplog.rs
2019-07-03T09:37:25.883+0000 I STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2019-07-03T09:37:25.884+0000 I STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2019-07-03T09:37:25.966+0000 I REPL     [replication-0] ******
2019-07-03T09:37:25.976+0000 I STORAGE  [replication-0] dropAllDatabasesExceptLocal 1
2019-07-03T09:37:25.978+0000 I ASIO     [RS] Connecting to mongo1:30001
2019-07-03T09:37:25.994+0000 I ASIO     [RS] Connecting to mongo1:30001
2019-07-03T09:37:26.008+0000 I REPL     [replication-1] CollectionCloner::start called, on ns:admin.system.version
2019-07-03T09:37:26.011+0000 I STORAGE  [repl writer worker 11] createCollection: admin.system.version with provided UUID: 42b9cfbb-81e0-4132-b96e-12043c67b340
2019-07-03T09:37:26.028+0000 I INDEX    [repl writer worker 11] build index on: admin.system.version properties: { v: 2, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" }
2019-07-03T09:37:26.029+0000 I INDEX    [repl writer worker 11] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2019-07-03T09:37:26.032+0000 I COMMAND  [repl writer worker 12] setting featureCompatibilityVersion to 4.0
2019-07-03T09:37:26.033+0000 I NETWORK  [repl writer worker 12] Skip closing connection for connection # 7
2019-07-03T09:37:26.034+0000 I NETWORK  [repl writer worker 12] Skip closing connection for connection # 2
2019-07-03T09:37:26.037+0000 I REPL     [repl writer worker 12] CollectionCloner ns:admin.system.version finished cloning with status: OK
2019-07-03T09:37:26.042+0000 I REPL     [repl writer worker 12] Finished cloning data: OK. Beginning oplog replay.
2019-07-03T09:37:26.044+0000 I REPL     [replication-0] No need to apply operations. (currently at { : Timestamp(1562146643, 1) })
2019-07-03T09:37:26.045+0000 I REPL     [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: error in fetcher batch callback: oplog fetcher is shutting down. Last fetched optime and hash: { ts: Timestamp(0, 0), t: -1 }[0]
2019-07-03T09:37:26.046+0000 I REPL     [replication-1] Initial sync attempt finishing up.
2019-07-03T09:37:26.046+0000 I REPL     [replication-1] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1562146645853), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp(1562146643, 1), initialSyncOplogEnd: Timestamp(1562146643, 1), databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1562146645998), end: new Date(1562146646043), elapsedMillis: 45, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 1, fetchedBatches: 1, start: new Date(1562146646009), end: new Date(1562146646043), elapsedMillis: 34 } } } }
2019-07-03T09:37:26.047+0000 I STORAGE  [replication-1] Finishing collection drop for local.temp_oplog_buffer (a8b0eb08-007c-4228-b957-923085d7972c).
2019-07-03T09:37:26.055+0000 I REPL     [replication-1] initial sync done; took 0s.
2019-07-03T09:37:26.055+0000 I REPL     [replication-1] transition to RECOVERING from STARTUP2
2019-07-03T09:37:26.056+0000 I REPL     [replication-1] Starting replication fetcher thread
2019-07-03T09:37:26.056+0000 I REPL     [replication-1] Starting replication applier thread
2019-07-03T09:37:26.057+0000 I REPL     [replication-1] Starting replication reporter thread
2019-07-03T09:37:26.057+0000 I REPL     [rsSync-0] Starting oplog application
2019-07-03T09:37:26.057+0000 I REPL     [rsBackgroundSync] could not find member to sync from
2019-07-03T09:37:26.059+0000 I REPL     [rsSync-0] transition to SECONDARY from RECOVERING
2019-07-03T09:37:26.060+0000 I REPL     [rsSync-0] Resetting sync source to empty, which was :27017
2019-07-03T09:37:26.061+0000 I REPL     [replexec-2] Member mongo2:30002 is now in state SECONDARY
2019-07-03T09:37:26.071+0000 I NETWORK  [listener] connection accepted from 172.22.0.4:60164 #12 (3 connections now open)
2019-07-03T09:37:26.074+0000 I NETWORK  [conn12] received client metadata from 172.22.0.4:60164 conn12: { driver: { name: "MongoDB Internal Client", version: "4.0.10" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2019-07-03T09:37:34.344+0000 I STORAGE  [conn2] createCollection: local.replset.election with generated UUID: fd4b9ce9-3f53-4ecd-b26c-a97bf7b0acfe
2019-07-03T09:37:34.486+0000 I NETWORK  [listener] connection accepted from 172.22.0.4:60170 #13 (4 connections now open)
2019-07-03T09:37:34.497+0000 I COMMAND  [conn2] command local.replset.election command: replSetRequestVotes { replSetRequestVotes: 1, setName: "my-mongo-set", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp(1562146643, 1), t: -1 }, $clusterTime: { clusterTime: Timestamp(1562146643, 1), signature: { hash: BinData(0, 0000000000000000000000000000000000000000), keyId: 0 } }, $db: "admin" } numYields:0 reslen:204 locks:{ Global: { acquireCount: { r: 3, w: 2 } }, Database: { acquireCount: { r: 1, W: 2 } }, Collection: { acquireCount: { r: 1 } } } storage:{} protocol:op_msg 151ms
2019-07-03T09:37:34.497+0000 I NETWORK  [listener] connection accepted from 172.22.0.4:60172 #14 (5 connections now open)
2019-07-03T09:37:34.501+0000 I NETWORK  [conn13] received client metadata from 172.22.0.4:60170 conn13: { driver: { name: "NetworkInterfaceTL", version: "4.0.10" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2019-07-03T09:37:34.506+0000 I NETWORK  [conn14] received client metadata from 172.22.0.4:60172 conn14: { driver: { name: "NetworkInterfaceTL", version: "4.0.10" }, os: { type: "Linux", name: "Ubuntu", architecture: "x86_64", version: "16.04" } }
2019-07-03T09:37:34.673+0000 I REPL     [replexec-2] Member mongo1:30001 is now in state PRIMARY
2019-07-03T09:37:36.007+0000 I CONNPOOL [RS] Ending connection to host mongo1:30001 due to bad connection status; 1 connections to that host remain open
2019-07-03T09:37:36.265+0000 I NETWORK  [conn12] end connection 172.22.0.4:60164 (4 connections now open)
2019-07-03T09:37:37.067+0000 I REPL     [rsBackgroundSync] sync source candidate: mongo1:30001
2019-07-03T09:37:37.075+0000 I REPL     [rsBackgroundSync] Changed sync source from empty to mongo1:30001
2019-07-03T09:37:37.077+0000 I ASIO     [RS] Connecting to mongo1:30001
2019-07-03T09:37:37.091+0000 I STORAGE  [replication-1] Triggering the first stable checkpoint. Initial Data: Timestamp(1562146643, 1) PrevStable: Timestamp(0, 0) CurrStable: Timestamp(1562146643, 1)
2019-07-03T09:37:37.099+0000 I STORAGE  [repl writer worker 0] createCollection: config.transactions with provided UUID: 57f8bbfa-dffd-43d1-9c26-30a92a70d24e
2019-07-03T09:37:37.153+0000 I STORAGE  [repl writer worker 2] createCollection: admin.system.keys with provided UUID: 519bcdaf-01e8-4b3d-877b-ef82dbb13e9a
2019-07-03T09:37:37.176+0000 I STORAGE  [repl writer worker 7] createCollection: test.todos with provided UUID: ee45b4c8-51d0-40f3-aedf-46597c5f3abe
2019-07-03T09:37:38.933+0000 I NETWORK  [listener] connection accepted from 172.22.0.5:43522 #16 (5 connections now open)
2019-07-03T09:37:38.953+0000 I NETWORK  [conn16] received client metadata from 172.22.0.5:43522 conn16: { driver: { name: "nodejs", version: "3.2.7" }, os: { type: "Linux", name: "linux", architecture: "x64", version: "4.9.125-linuxkit" }, platform: "Node.js v7.10.1, LE, mongodb-core: 3.2.7" }
2019-07-03T09:37:39.132+0000 I STORAGE  [repl writer worker 13] createCollection: test.tasks with provided UUID: baf7e5cf-ad74-434d-a047-bb452d002de5
2019-07-03T09:37:44.342+0000 I NETWORK  [conn2] end connection 172.22.0.4:60134 (4 connections now open)
